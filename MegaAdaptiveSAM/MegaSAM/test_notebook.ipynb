{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm, trange\n",
    "# from sklearn import datasets\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "from sam.sam import SAM\n",
    "\n",
    "from mega_sam_feri import MegaSAM\n",
    "from NN_utils import train_multi_model\n",
    "from data.mnist import mnist_data_gen\n",
    "\n",
    "#import sys; sys.path.append(\"..\")\n",
    "#sys.path.append(\"sam\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set, test_set= mnist_data_gen()\n",
    "\n",
    "training_set = [(i[0].flatten(), i[1]) for i in training_set]\n",
    "test_set = [(i[0].flatten(), i[1]) for i in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = 16\n",
    "output2 = 16\n",
    "\n",
    "MLP = nn.Sequential(\n",
    "    nn.Linear(28 * 28, output1),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(output1, output2),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(output2, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66497e2eeef432eb6fdad431e1f10a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\szilv\\OneDrive\\Dokumentumok\\summer_2022\\Summer-2022\\MegaAdaptiveSAM\\MegaSAM\\test_notebook.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/szilv/OneDrive/Dokumentumok/summer_2022/Summer-2022/MegaAdaptiveSAM/MegaSAM/test_notebook.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model, training_losses, training_accuracies, validation_accuracies \u001b[39m=\u001b[39m train_multi_model(train_data\u001b[39m=\u001b[39;49mtraining_set, test_data\u001b[39m=\u001b[39;49mtest_set, model\u001b[39m=\u001b[39;49mMLP,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/szilv/OneDrive/Dokumentumok/summer_2022/Summer-2022/MegaAdaptiveSAM/MegaSAM/test_notebook.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                         optim\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mMegaSAM\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, tracking\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\szilv\\OneDrive\\Dokumentumok\\summer_2022\\Summer-2022\\MegaAdaptiveSAM\\MegaSAM\\NN_utils.py:218\u001b[0m, in \u001b[0;36mtrain_multi_model\u001b[1;34m(model, train_data, test_data, optim, batch_size, epochs, tracking, shuffle_loader, lr, momentum, criterion, rho)\u001b[0m\n\u001b[0;32m    216\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m    217\u001b[0m \u001b[39mif\u001b[39;00m optim \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSAM\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m optim \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mMegaSAM\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 218\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep(closure)\n\u001b[0;32m    219\u001b[0m \u001b[39mif\u001b[39;00m optim \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSAM\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m optim \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mMegaSAM\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    220\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\szilv\\OneDrive\\Dokumentumok\\summer_2022\\summer_venv\\lib\\site-packages\\torch\\optim\\optimizer.py:109\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    107\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m    108\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 109\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\szilv\\OneDrive\\Dokumentumok\\summer_2022\\summer_venv\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\szilv\\OneDrive\\Dokumentumok\\summer_2022\\Summer-2022\\MegaAdaptiveSAM\\MegaSAM\\mega_sam_feri.py:78\u001b[0m, in \u001b[0;36mMegaSAM.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[39mif\u001b[39;00m closure \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     77\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSharpness Aware Minimization requires closure, but it was not provided\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 78\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_zero_M_grad()\n\u001b[0;32m     79\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39menable_grad():\n\u001b[0;32m     80\u001b[0m     penalized_mloss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmloss() \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmpenalty()\n",
      "File \u001b[1;32mc:\\Users\\szilv\\OneDrive\\Dokumentumok\\summer_2022\\Summer-2022\\MegaAdaptiveSAM\\MegaSAM\\mega_sam_feri.py:100\u001b[0m, in \u001b[0;36mMegaSAM._zero_M_grad\u001b[1;34m(set_to_none)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_zero_M_grad\u001b[39m(set_to_none\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 100\u001b[0m     \u001b[39mfor\u001b[39;00m M_param_group \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39mM_param_groups:\n\u001b[0;32m    101\u001b[0m         \u001b[39mfor\u001b[39;00m M \u001b[39min\u001b[39;00m M_param_group:\n\u001b[0;32m    102\u001b[0m             \u001b[39mif\u001b[39;00m set_to_none:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "model, training_losses, training_accuracies, validation_accuracies = train_multi_model(train_data=training_set, test_data=test_set, model=MLP,\n",
    "                        optim=\"MegaSAM\", batch_size=1000, epochs=5, tracking=True)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAM training accuracies: [0.9355499744415283, 0.9374833106994629, 0.9383666515350342, 0.9388333559036255, 0.9392833113670349]\n",
      "SAM validation accuracies: [0.9351000189781189, 0.9362000226974487, 0.9362000226974487, 0.9363999962806702, 0.9361000061035156]\n"
     ]
    }
   ],
   "source": [
    "print(f\"SAM training accuracies: {training_accuracies}\")\n",
    "print(f\"SAM validation accuracies: {validation_accuracies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# be careful with comparisons, you have to restart the kernel every time to initialize a new model\n",
    "from test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'params': [Parameter containing:\n",
      "tensor([[-0.0199, -0.0264, -0.0170,  ...,  0.0081, -0.0207, -0.0153],\n",
      "        [ 0.0275,  0.0293,  0.0002,  ..., -0.0013,  0.0038,  0.0120],\n",
      "        [-0.0076, -0.0163, -0.0095,  ...,  0.0137, -0.0054, -0.0256],\n",
      "        ...,\n",
      "        [ 0.0148, -0.0022,  0.0238,  ...,  0.0059, -0.0233, -0.0225],\n",
      "        [ 0.0115,  0.0139,  0.0069,  ..., -0.0035, -0.0315,  0.0075],\n",
      "        [-0.0104, -0.0081, -0.0148,  ..., -0.0255,  0.0064,  0.0324]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.2136,  0.6410,  0.4412, -0.0215,  0.0705,  0.0549,  0.5862,  0.0044,\n",
      "         0.2059, -0.0072, -0.0377,  0.8167,  0.6488, -0.3296, -0.9736, -0.0623],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.2564,  0.6284, -0.1144,  0.0992,  0.0514, -0.4919, -0.1882,  0.0763,\n",
      "          0.9567,  0.0837,  0.1264, -0.2194, -0.1003, -0.4149,  0.0261,  0.1435],\n",
      "        [ 0.0306,  0.4215, -0.2447,  0.2158,  0.2035,  0.0803, -0.2460,  0.0249,\n",
      "         -0.4432, -0.1980,  0.0580,  0.1566,  0.5042, -0.5949, -0.6725, -0.2409],\n",
      "        [-0.3549,  0.2680, -0.9278,  0.1832,  0.1673,  0.6667, -0.8605, -0.1413,\n",
      "         -0.9823,  0.1034,  0.1929,  0.2491,  0.1398, -0.1656,  0.2456,  0.2929],\n",
      "        [-0.4537, -0.5045,  0.1243, -0.1373, -0.8339, -0.5677,  0.4499,  0.2090,\n",
      "         -0.5297,  0.1144,  0.1222,  0.2939, -0.2323,  0.1254, -0.2659, -0.0565],\n",
      "        [-0.2072, -0.2118,  0.2348, -0.1292, -0.0203,  0.6682, -0.0731, -0.0959,\n",
      "         -0.1950, -0.2713,  0.0182,  1.0562,  0.4316, -0.5171, -0.3342,  0.1555],\n",
      "        [ 0.7122, -0.1236, -0.8771,  0.1588, -0.5229,  1.0561,  0.1384, -0.1979,\n",
      "         -0.0971,  0.0117, -0.1267,  0.0442,  0.3418, -0.2040, -0.2273,  0.0096],\n",
      "        [-0.9461, -0.7114, -0.1749,  0.1077, -0.4758, -0.2172, -0.0333, -0.0465,\n",
      "          0.0419,  0.2048, -0.1356, -0.7972,  1.0311, -0.2177,  0.2727, -0.0197],\n",
      "        [ 0.2702, -0.9917,  0.4084, -0.0756,  0.0650,  0.0728,  0.3222,  0.0233,\n",
      "         -0.3415, -0.1171, -0.2438, -0.3493, -0.5956, -0.4923,  0.4383, -0.2515],\n",
      "        [-0.1638, -0.1017, -0.1157,  0.2020, -0.1830, -0.1295, -0.0652,  0.0352,\n",
      "          0.1489,  0.0138, -0.2073,  0.0154,  0.0683, -0.0803, -0.2174, -0.2108],\n",
      "        [-0.4028,  0.6432, -0.4369,  0.1328, -0.1089, -0.8097, -0.1441, -0.1114,\n",
      "         -0.0370, -0.0086,  0.0237, -0.7022,  0.7810,  0.6330, -0.9772, -0.3123],\n",
      "        [ 0.0858, -0.5403,  0.2241,  0.1049, -0.6546, -0.0536,  0.5173,  0.0122,\n",
      "         -0.1700, -0.4172,  0.1498,  0.5633, -0.4528,  0.9821, -0.6991, -0.0881],\n",
      "        [ 0.4360, -0.1629, -0.5697,  0.1519,  0.1077, -0.1938, -0.5731, -0.2448,\n",
      "          0.6036, -0.3123, -0.0206, -0.7426, -0.4713,  0.6224,  0.2156, -0.0618],\n",
      "        [-0.1357, -0.1548, -0.1277, -0.2263,  0.0045, -0.0654, -0.2222,  0.1558,\n",
      "         -0.0720, -0.1503,  0.1906, -0.1768,  0.1507, -0.1820, -0.2275, -0.0080],\n",
      "        [-0.2459,  0.0991, -0.1889,  0.1884, -0.3317, -0.0729, -0.4594,  0.1042,\n",
      "         -0.2239,  0.1796,  0.2474,  0.2253, -0.0728,  0.0083,  0.4734,  0.3575],\n",
      "        [-0.3739,  0.3172,  0.3070, -0.2393, -0.7084, -0.3983,  0.5310, -0.1150,\n",
      "          0.1299,  0.4100, -0.2376, -0.2198,  0.3899, -0.5342,  0.2552,  0.2873],\n",
      "        [-0.2292,  0.0622,  0.4992,  0.1252,  0.5069,  0.1700, -0.4539,  0.1523,\n",
      "          0.2141, -0.1585, -0.1701, -0.0130, -0.7009,  0.2413, -0.8455, -0.2405]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.2118,  0.7797,  0.3814,  0.0975, -0.2022,  0.0640, -0.0447,  0.0945,\n",
      "         0.0531,  0.3375, -0.2767,  0.3663, -0.1326, -0.0071,  0.3542, -0.3905],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 7.5320e-02,  4.5078e-02, -1.8984e-01, -3.7840e-01,  2.9529e-01,\n",
      "         -4.6816e-01, -2.5813e-01,  6.6703e-01,  6.6684e-02, -2.8240e-01,\n",
      "         -1.5530e-01, -3.0878e-01,  6.8096e-02, -1.8971e-01, -3.9421e-01,\n",
      "          7.3958e-01],\n",
      "        [-3.7896e-01, -5.0936e-02, -6.0582e-01, -1.6874e-01,  1.0085e-02,\n",
      "          3.7813e-02,  1.1676e+00, -9.6613e-01, -8.5198e-02,  6.2412e-01,\n",
      "          6.2001e-02,  5.5345e-01, -1.5986e-01, -2.7638e-02, -2.8336e-03,\n",
      "         -7.3691e-01],\n",
      "        [ 5.3279e-01, -2.7921e-01, -1.6240e-03,  3.3249e-02, -2.1664e-02,\n",
      "         -4.5096e-01, -1.7220e-01, -1.5789e-01, -1.5734e-02,  3.2230e-01,\n",
      "          3.7368e-01,  7.3741e-01, -1.2636e-01,  1.2306e-01, -1.4638e-01,\n",
      "          4.7539e-01],\n",
      "        [-6.2995e-03,  3.7528e-01, -5.9156e-01,  1.8236e-01, -2.4019e-01,\n",
      "          5.8352e-01, -4.7043e-02,  3.6906e-01, -3.5801e-03, -1.7941e-01,\n",
      "          3.9176e-01,  5.7312e-01, -1.6160e-03,  7.5840e-02, -2.8726e-01,\n",
      "         -1.2285e-01],\n",
      "        [ 4.7052e-01, -2.6466e-01,  2.6408e-02, -3.5285e-01, -2.8205e-01,\n",
      "         -3.4480e-01,  3.2024e-01, -3.4812e-01,  2.0615e-01, -3.2751e-01,\n",
      "         -4.3267e-01, -3.3739e-01,  6.5132e-02,  1.9952e-01,  8.1870e-01,\n",
      "          3.3730e-01],\n",
      "        [-5.1467e-02,  1.7400e-01,  2.8287e-01, -9.8376e-02,  5.6937e-01,\n",
      "          4.2586e-01, -1.6129e-01,  1.6396e-01, -1.8765e-01, -2.0564e-02,\n",
      "         -2.4419e-01, -4.3704e-01,  1.6187e-01, -1.5597e-01, -5.2273e-01,\n",
      "         -2.6340e-01],\n",
      "        [ 2.0780e-01,  4.6293e-01,  5.7051e-01, -2.4900e-01, -3.0523e-01,\n",
      "         -5.8832e-01, -4.2065e-01, -2.3497e-01, -1.4476e-01,  8.5934e-01,\n",
      "         -4.9057e-01, -6.7917e-01,  2.0566e-01, -1.1088e-01, -1.8116e-01,\n",
      "          3.1378e-01],\n",
      "        [-6.8103e-02, -2.5563e-01, -2.7857e-01,  6.1994e-01,  2.7813e-01,\n",
      "         -1.4890e-01,  5.7913e-02,  9.8816e-02, -2.1753e-01,  5.4549e-03,\n",
      "          6.9874e-01,  3.2543e-02,  2.0560e-01,  3.0173e-01,  4.4066e-01,\n",
      "         -3.2202e-01],\n",
      "        [-2.1075e-02, -2.3914e-01,  5.6984e-01,  1.2350e-01, -3.4493e-01,\n",
      "         -3.6803e-01,  4.2668e-01,  4.0695e-01,  1.7035e-02,  1.9187e-02,\n",
      "         -1.5904e-01,  3.9827e-01, -7.8957e-02,  3.5272e-01, -3.0388e-01,\n",
      "         -3.0102e-01],\n",
      "        [-3.8025e-01, -7.1593e-01, -2.8385e-01,  3.8922e-01, -1.5723e-01,\n",
      "          3.9188e-01,  3.5009e-01,  4.9245e-01,  1.0663e-01, -5.6027e-01,\n",
      "         -1.9227e-01, -2.2094e-01, -2.6161e-04, -2.6431e-01,  8.7639e-01,\n",
      "          5.9255e-02]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4741,  0.0840, -0.3744,  0.2787,  0.1258,  0.7901, -0.2336, -0.7585,\n",
      "         0.8707,  0.0498], requires_grad=True)], 'rho': 0.05, 'trace_penalty': True, 'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False}, {'params': [tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]], requires_grad=True), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True), tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "       requires_grad=True), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True), tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "       requires_grad=True), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)], 'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc02a9fce464d9a9e04be4f82df628e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e20cef7aee96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model, training_losses, training_accuracies, validation_accuracies = train_multi_model(train_data=training_set, test_data=test_set, model=MLP,\n\u001b[0m\u001b[1;32m      2\u001b[0m                         optim=\"MegaSAM\", batch_size=100, epochs=5, tracking=True)\n",
      "\u001b[0;32m~/Summer_2022/Summer-2022/MegaAdaptiveSAM/MegaSAM/NN_utils.py\u001b[0m in \u001b[0;36mtrain_multi_model\u001b[0;34m(model, train_data, test_data, optim, batch_size, epochs, tracking, shuffle_loader, lr, momentum, criterion, rho)\u001b[0m\n\u001b[1;32m    222\u001b[0m                         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumbers2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Maybe we have to fix things here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                         \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                         \u001b[0mpredictions2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                         \u001b[0;31m# print(predictions2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m         \u001b[0mforward_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m         \u001b[0;31m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;31m# this function, and just call forward.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, training_losses, training_accuracies, validation_accuracies = train_multi_model(train_data=training_set, test_data=test_set, model=MLP,\n",
    "                        optim=\"MegaSAM\", batch_size=100, epochs=5, tracking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAM training accuracies: [0.8651666641235352]\n",
      "SAM validation accuracies: [0.9218999743461609]\n"
     ]
    }
   ],
   "source": [
    "print(f\"SAM training accuracies: {training_accuracies}\")\n",
    "print(f\"SAM validation accuracies: {validation_accuracies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
